{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from smt.surrogate_models import KRG, RBF\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import keras\n",
    "from keras import layers\n",
    "import keras_tuner\n",
    "\n",
    "#LSTM batch normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Monte_Carlo_10000/training_data_bending.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['outer_wall_thickness', 'inside_wall_side_thickness', 'inside_wall_middle_thickness', 'height', 'width', 'sigma0', 'youngs']].values\n",
    "Y = df[['max_force']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "    #model.add(layers.Dropout(rate=0.2))\n",
    "    #activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "    units = hp.Int('units', min_value=16, max_value=128, step=16)\n",
    "    num_layers = hp.Int('num_layers', 1, 10)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    for i in range(num_layers):\n",
    "        model.add(layers.Dense(\n",
    "            units=units, \n",
    "            activation='relu',\n",
    "            ))\n",
    "        #model.add(layers.Dropout(rate=0.5))\n",
    "    model.add(layers.Dense(\n",
    "        units=1, \n",
    "        activation='relu'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.legacy.Adam(learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "hp = keras_tuner.HyperParameters()\n",
    "build_model(hp)\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective='mse',\n",
    "    max_trials=200,\n",
    "    executions_per_trial=3,\n",
    "    directory='keras_tuner4',\n",
    "    project_name='test_4'\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 10, 'step': 1, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 Complete [00h 01m 07s]\n",
      "mse: 0.25238431617617607\n",
      "\n",
      "Best mse So Far: 0.02261369116604328\n",
      "Total elapsed time: 00h 38m 25s\n",
      "\n",
      "Search: Running Trial #108\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "80                |80                |units\n",
      "2                 |6                 |num_layers\n",
      "0.001             |0.01              |learning_rate\n",
      "\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 926.1906 - mse: 926.1906 - val_loss: 888.0174 - val_mse: 888.0174\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 909.3926 - mse: 909.3926 - val_loss: 872.2686 - val_mse: 872.2686\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 892.6073 - mse: 892.6073 - val_loss: 856.7174 - val_mse: 856.7174\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 875.9183 - mse: 875.9183 - val_loss: 840.3693 - val_mse: 840.3693\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 858.4039 - mse: 858.4039 - val_loss: 822.8145 - val_mse: 822.8145\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 839.6136 - mse: 839.6136 - val_loss: 803.5009 - val_mse: 803.5009\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 819.1979 - mse: 819.1979 - val_loss: 782.3251 - val_mse: 782.3251\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 796.0880 - mse: 796.0880 - val_loss: 759.1362 - val_mse: 759.1362\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 771.0998 - mse: 771.0998 - val_loss: 733.6217 - val_mse: 733.6217\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 743.9489 - mse: 743.9489 - val_loss: 705.5182 - val_mse: 705.5182\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 713.9409 - mse: 713.9409 - val_loss: 674.7670 - val_mse: 674.7670\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 681.2140 - mse: 681.2140 - val_loss: 641.2189 - val_mse: 641.2189\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 645.0034 - mse: 645.0034 - val_loss: 604.8312 - val_mse: 604.8312\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 606.5132 - mse: 606.5132 - val_loss: 565.4764 - val_mse: 565.4764\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 564.8550 - mse: 564.8550 - val_loss: 523.4351 - val_mse: 523.4351\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 520.1715 - mse: 520.1715 - val_loss: 478.8236 - val_mse: 478.8236\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 473.3229 - mse: 473.3229 - val_loss: 432.1143 - val_mse: 432.1143\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 424.8602 - mse: 424.8602 - val_loss: 383.8446 - val_mse: 383.8446\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 374.7714 - mse: 374.7714 - val_loss: 334.8390 - val_mse: 334.8390\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 324.2639 - mse: 324.2639 - val_loss: 285.9249 - val_mse: 285.9249\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 274.3695 - mse: 274.3695 - val_loss: 238.1232 - val_mse: 238.1232\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 225.9842 - mse: 225.9842 - val_loss: 192.5447 - val_mse: 192.5447\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 180.8859 - mse: 180.8859 - val_loss: 150.3132 - val_mse: 150.3132\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 139.6282 - mse: 139.6282 - val_loss: 112.6661 - val_mse: 112.6661\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 103.8215 - mse: 103.8215 - val_loss: 80.6838 - val_mse: 80.6838\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 74.2434 - mse: 74.2434 - val_loss: 55.1237 - val_mse: 55.1237\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 52.1915 - mse: 52.1915 - val_loss: 36.1936 - val_mse: 36.1936\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 36.1799 - mse: 36.1799 - val_loss: 23.7209 - val_mse: 23.7209\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 26.7627 - mse: 26.7627 - val_loss: 16.6163 - val_mse: 16.6163\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 23.6867 - mse: 23.6867 - val_loss: 13.4851 - val_mse: 13.4851\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 22.8906 - mse: 22.8906 - val_loss: 12.8409 - val_mse: 12.8409\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 23.9870 - mse: 23.9870 - val_loss: 13.1754 - val_mse: 13.1754\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 25.5503 - mse: 25.5503 - val_loss: 13.5414 - val_mse: 13.5414\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 26.1840 - mse: 26.1840 - val_loss: 13.4650 - val_mse: 13.4650\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 25.9424 - mse: 25.9424 - val_loss: 13.1010 - val_mse: 13.1010\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 25.1682 - mse: 25.1682 - val_loss: 12.5695 - val_mse: 12.5695\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 24.1568 - mse: 24.1568 - val_loss: 12.1398 - val_mse: 12.1398\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 22.8382 - mse: 22.8382 - val_loss: 11.9416 - val_mse: 11.9416\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 22.0627 - mse: 22.0627 - val_loss: 11.9689 - val_mse: 11.9689\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 21.5910 - mse: 21.5910 - val_loss: 12.1630 - val_mse: 12.1630\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 21.1770 - mse: 21.1770 - val_loss: 12.3724 - val_mse: 12.3724\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 21.1199 - mse: 21.1199 - val_loss: 12.5881 - val_mse: 12.5881\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 21.0140 - mse: 21.0140 - val_loss: 12.6683 - val_mse: 12.6683\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 20.8981 - mse: 20.8981 - val_loss: 12.5966 - val_mse: 12.5966\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 20.7257 - mse: 20.7257 - val_loss: 12.4112 - val_mse: 12.4112\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 20.5566 - mse: 20.5566 - val_loss: 12.1528 - val_mse: 12.1528\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 20.3223 - mse: 20.3223 - val_loss: 11.8997 - val_mse: 11.8997\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 20.1381 - mse: 20.1381 - val_loss: 11.6090 - val_mse: 11.6090\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 19.9111 - mse: 19.9111 - val_loss: 11.3605 - val_mse: 11.3605\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 19.7046 - mse: 19.7046 - val_loss: 11.1253 - val_mse: 11.1253\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 19.5159 - mse: 19.5159 - val_loss: 10.8915 - val_mse: 10.8915\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 19.3351 - mse: 19.3351 - val_loss: 10.6534 - val_mse: 10.6534\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19.1513 - mse: 19.1513 - val_loss: 10.4297 - val_mse: 10.4297\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18.9734 - mse: 18.9734 - val_loss: 10.2213 - val_mse: 10.2213\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18.8095 - mse: 18.8095 - val_loss: 10.0384 - val_mse: 10.0384\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18.6212 - mse: 18.6212 - val_loss: 9.9069 - val_mse: 9.9069\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 18.4324 - mse: 18.4324 - val_loss: 9.8128 - val_mse: 9.8128\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18.2227 - mse: 18.2227 - val_loss: 9.7757 - val_mse: 9.7757\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 18.0003 - mse: 18.0003 - val_loss: 9.7412 - val_mse: 9.7412\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 17.8513 - mse: 17.8513 - val_loss: 9.7602 - val_mse: 9.7602\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 17.6594 - mse: 17.6594 - val_loss: 9.6630 - val_mse: 9.6630\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17.4727 - mse: 17.4727 - val_loss: 9.5125 - val_mse: 9.5125\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 17.2822 - mse: 17.2822 - val_loss: 9.3179 - val_mse: 9.3179\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17.0814 - mse: 17.0814 - val_loss: 9.1249 - val_mse: 9.1249\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 16.8903 - mse: 16.8903 - val_loss: 8.9663 - val_mse: 8.9663\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 16.6817 - mse: 16.6817 - val_loss: 8.8422 - val_mse: 8.8422\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16.4887 - mse: 16.4887 - val_loss: 8.7100 - val_mse: 8.7100\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16.3111 - mse: 16.3111 - val_loss: 8.5889 - val_mse: 8.5889\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16.1323 - mse: 16.1323 - val_loss: 8.4718 - val_mse: 8.4718\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 15.9154 - mse: 15.9154 - val_loss: 8.2776 - val_mse: 8.2776\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 15.7223 - mse: 15.7223 - val_loss: 8.0915 - val_mse: 8.0915\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 15.5111 - mse: 15.5111 - val_loss: 7.9412 - val_mse: 7.9412\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 15.3260 - mse: 15.3260 - val_loss: 7.7894 - val_mse: 7.7894\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 15.1387 - mse: 15.1387 - val_loss: 7.6234 - val_mse: 7.6234\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 14.9328 - mse: 14.9328 - val_loss: 7.4504 - val_mse: 7.4504\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 14.7709 - mse: 14.7709 - val_loss: 7.2786 - val_mse: 7.2786\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 14.5493 - mse: 14.5493 - val_loss: 7.1926 - val_mse: 7.1926\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 14.3598 - mse: 14.3598 - val_loss: 7.1278 - val_mse: 7.1278\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 14.1662 - mse: 14.1662 - val_loss: 7.1043 - val_mse: 7.1043\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 14.0124 - mse: 14.0124 - val_loss: 7.0162 - val_mse: 7.0162\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 13.8360 - mse: 13.8360 - val_loss: 6.9756 - val_mse: 6.9756\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 13.6750 - mse: 13.6750 - val_loss: 6.9003 - val_mse: 6.9003\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 13.5006 - mse: 13.5006 - val_loss: 6.8311 - val_mse: 6.8311\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 13.3400 - mse: 13.3400 - val_loss: 6.6798 - val_mse: 6.6798\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 13.1487 - mse: 13.1487 - val_loss: 6.5095 - val_mse: 6.5095\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 12.9606 - mse: 12.9606 - val_loss: 6.3444 - val_mse: 6.3444\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 12.7682 - mse: 12.7682 - val_loss: 6.1674 - val_mse: 6.1674\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 12.5955 - mse: 12.5955 - val_loss: 5.9784 - val_mse: 5.9784\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 12.4083 - mse: 12.4083 - val_loss: 5.8022 - val_mse: 5.8022\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 12.2361 - mse: 12.2361 - val_loss: 5.6358 - val_mse: 5.6358\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 12.0774 - mse: 12.0774 - val_loss: 5.4623 - val_mse: 5.4623\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 11.9308 - mse: 11.9308 - val_loss: 5.3450 - val_mse: 5.3450\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 11.7414 - mse: 11.7414 - val_loss: 5.2917 - val_mse: 5.2917\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 11.5598 - mse: 11.5598 - val_loss: 5.2956 - val_mse: 5.2956\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 11.4146 - mse: 11.4146 - val_loss: 5.3000 - val_mse: 5.3000\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 11.2551 - mse: 11.2551 - val_loss: 5.2802 - val_mse: 5.2802\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 11.1109 - mse: 11.1109 - val_loss: 5.2387 - val_mse: 5.2387\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 10.9550 - mse: 10.9550 - val_loss: 5.1144 - val_mse: 5.1144\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 10.7932 - mse: 10.7932 - val_loss: 5.0010 - val_mse: 5.0010\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 10.6542 - mse: 10.6542 - val_loss: 4.8355 - val_mse: 4.8355\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 10.4705 - mse: 10.4705 - val_loss: 4.7260 - val_mse: 4.7260\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 10.3156 - mse: 10.3156 - val_loss: 4.6276 - val_mse: 4.6276\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 10.1670 - mse: 10.1670 - val_loss: 4.4899 - val_mse: 4.4899\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 10.0168 - mse: 10.0168 - val_loss: 4.3737 - val_mse: 4.3737\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 9.8700 - mse: 9.8700 - val_loss: 4.2932 - val_mse: 4.2932\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 9.7305 - mse: 9.7305 - val_loss: 4.2141 - val_mse: 4.2141\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 9.5751 - mse: 9.5751 - val_loss: 4.1581 - val_mse: 4.1581\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 9.4315 - mse: 9.4315 - val_loss: 4.1114 - val_mse: 4.1114\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 9.2735 - mse: 9.2735 - val_loss: 4.0995 - val_mse: 4.0995\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 9.1513 - mse: 9.1513 - val_loss: 4.1051 - val_mse: 4.1051\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 9.0135 - mse: 9.0135 - val_loss: 4.0660 - val_mse: 4.0660\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 8.8916 - mse: 8.8916 - val_loss: 4.0222 - val_mse: 4.0222\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 8.7521 - mse: 8.7521 - val_loss: 3.8928 - val_mse: 3.8928\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 189ms/step - loss: 8.5983 - mse: 8.5983 - val_loss: 3.7881 - val_mse: 3.7881\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 8.4686 - mse: 8.4686 - val_loss: 3.6938 - val_mse: 3.6938\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 8.3398 - mse: 8.3398 - val_loss: 3.6136 - val_mse: 3.6136\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 2s 812ms/step - loss: 8.2005 - mse: 8.2005 - val_loss: 3.5748 - val_mse: 3.5748\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 220ms/step - loss: 8.0852 - mse: 8.0852 - val_loss: 3.5520 - val_mse: 3.5520\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 199ms/step - loss: 7.9561 - mse: 7.9561 - val_loss: 3.5026 - val_mse: 3.5026\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 7.8472 - mse: 7.8472 - val_loss: 3.4211 - val_mse: 3.4211\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 7.7205 - mse: 7.7205 - val_loss: 3.3551 - val_mse: 3.3551\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 7.5843 - mse: 7.5843 - val_loss: 3.3457 - val_mse: 3.3457\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 7.4753 - mse: 7.4753 - val_loss: 3.3539 - val_mse: 3.3539\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 7.3608 - mse: 7.3608 - val_loss: 3.3423 - val_mse: 3.3423\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 1s 302ms/step - loss: 7.2524 - mse: 7.2524 - val_loss: 3.2874 - val_mse: 3.2874\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 7.1410 - mse: 7.1410 - val_loss: 3.2274 - val_mse: 3.2274\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 7.0241 - mse: 7.0241 - val_loss: 3.1268 - val_mse: 3.1268\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 6.9114 - mse: 6.9114 - val_loss: 3.0663 - val_mse: 3.0663\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 6.7901 - mse: 6.7901 - val_loss: 3.0450 - val_mse: 3.0450\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 6.6933 - mse: 6.6933 - val_loss: 2.9877 - val_mse: 2.9877\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 192ms/step - loss: 6.5746 - mse: 6.5746 - val_loss: 2.9546 - val_mse: 2.9546\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 6.4820 - mse: 6.4820 - val_loss: 2.9323 - val_mse: 2.9323\n",
      "Epoch 133/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.5940 - mse: 7.5940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Retrieve the hyperparameters and performance\u001b[39;00m\n\u001b[1;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1777\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1778\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1790\u001b[0m     )\n\u001b[0;32m-> 1791\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1804\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1806\u001b[0m }\n\u001b[1;32m   1807\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:2189\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2188\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_test_begin()\n\u001b[0;32m-> 2189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m   2190\u001b[0m     _,\n\u001b[1;32m   2191\u001b[0m     dataset_or_iterator,\n\u001b[1;32m   2192\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1331\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1331\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:506\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:710\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    706\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 710\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    747\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    748\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 749\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3420\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3419\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3420\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3421\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3423\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, Y_val), \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Retrieve the hyperparameters and performance\n",
    "results = []\n",
    "for trial in tuner.oracle.get_best_trials(num_trials=100):\n",
    "    result = {\n",
    "        'units': trial.hyperparameters.get(f'units'),\n",
    "        'num_layers': trial.hyperparameters.get('num_layers'),\n",
    "        'learning_rate': trial.hyperparameters.get('learning_rate'),\n",
    "        'mse': trial.score\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "hyperparameters_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                512       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17217 (67.25 KB)\n",
      "Trainable params: 17217 (67.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=5)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in keras_tuner3/test_3\n",
      "Showing 10 best trials\n",
      "Objective(name=\"mse\", direction=\"min\")\n",
      "\n",
      "Trial 090 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "num_layers: 5\n",
      "learning_rate: 0.001\n",
      "Score: 0.01339293085038662\n",
      "\n",
      "Trial 034 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "num_layers: 7\n",
      "learning_rate: 0.001\n",
      "Score: 0.016007056459784508\n",
      "\n",
      "Trial 041 summary\n",
      "Hyperparameters:\n",
      "units: 96\n",
      "num_layers: 10\n",
      "learning_rate: 0.01\n",
      "Score: 0.016132449731230736\n",
      "\n",
      "Trial 024 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "num_layers: 8\n",
      "learning_rate: 0.001\n",
      "Score: 0.016957532614469528\n",
      "\n",
      "Trial 088 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "num_layers: 10\n",
      "learning_rate: 0.01\n",
      "Score: 0.018046870827674866\n",
      "\n",
      "Trial 050 summary\n",
      "Hyperparameters:\n",
      "units: 80\n",
      "num_layers: 6\n",
      "learning_rate: 0.01\n",
      "Score: 0.018546711653470993\n",
      "\n",
      "Trial 000 summary\n",
      "Hyperparameters:\n",
      "units: 48\n",
      "num_layers: 8\n",
      "learning_rate: 0.01\n",
      "Score: 0.018668944016098976\n",
      "\n",
      "Trial 074 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "num_layers: 5\n",
      "learning_rate: 0.001\n",
      "Score: 0.01875992864370346\n",
      "\n",
      "Trial 025 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "num_layers: 4\n",
      "learning_rate: 0.01\n",
      "Score: 0.02201966382563114\n",
      "\n",
      "Trial 017 summary\n",
      "Hyperparameters:\n",
      "units: 80\n",
      "num_layers: 5\n",
      "learning_rate: 0.001\n",
      "Score: 0.022571105509996414\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 916.8267 - val_loss: 847.1415\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 810.0555 - val_loss: 649.8571\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 493.8049 - val_loss: 170.8901\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 92.1005 - val_loss: 162.7736\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 104.9221 - val_loss: 10.7857\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 49.2857 - val_loss: 78.2435\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 61.9031 - val_loss: 18.6374\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9018 - val_loss: 21.7504\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.7419 - val_loss: 5.1642\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.8328 - val_loss: 13.0446\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 13.8688 - val_loss: 4.7432\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.9529 - val_loss: 5.1979\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.6896 - val_loss: 4.3224\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7.3415 - val_loss: 3.4142\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3054 - val_loss: 2.7997\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3612 - val_loss: 2.3919\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0410 - val_loss: 2.2644\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4630 - val_loss: 1.9158\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0081 - val_loss: 1.8301\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4660 - val_loss: 1.9782\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.0741 - val_loss: 1.7823\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9099 - val_loss: 1.8470\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8038 - val_loss: 1.8788\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4876 - val_loss: 1.7782\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3173 - val_loss: 1.9031\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2137 - val_loss: 1.6458\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1265 - val_loss: 1.6679\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0035 - val_loss: 1.4162\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9123 - val_loss: 1.3185\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8050 - val_loss: 1.1889\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7183 - val_loss: 1.1051\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6746 - val_loss: 0.9998\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6545 - val_loss: 0.9957\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.8994\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5283 - val_loss: 0.8679\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5371 - val_loss: 0.8171\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5154 - val_loss: 0.7952\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4818 - val_loss: 0.6805\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4444 - val_loss: 0.6759\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4125 - val_loss: 0.6318\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3909 - val_loss: 0.5904\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3766 - val_loss: 0.5735\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3593 - val_loss: 0.5551\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3291 - val_loss: 0.5326\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3251 - val_loss: 0.4965\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.4975\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3045 - val_loss: 0.4682\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2926 - val_loss: 0.4755\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2688 - val_loss: 0.4167\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3135 - val_loss: 0.3986\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3045 - val_loss: 0.4195\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2865 - val_loss: 0.3711\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2358 - val_loss: 0.3843\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2202 - val_loss: 0.3502\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2556 - val_loss: 0.3404\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2189 - val_loss: 0.3182\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2039 - val_loss: 0.3132\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1976 - val_loss: 0.2900\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1960 - val_loss: 0.2953\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1996 - val_loss: 0.2863\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2185 - val_loss: 0.3921\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2434 - val_loss: 0.2567\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1982 - val_loss: 0.2502\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1858 - val_loss: 0.2415\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.2309\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1534 - val_loss: 0.2344\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1517 - val_loss: 0.2416\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1449 - val_loss: 0.2384\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1501 - val_loss: 0.2445\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1390 - val_loss: 0.2594\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1589 - val_loss: 0.2284\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1554 - val_loss: 0.2405\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1457 - val_loss: 0.3065\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.3165\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2048 - val_loss: 0.2243\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.2280\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1337 - val_loss: 0.2216\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1221 - val_loss: 0.1968\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1102 - val_loss: 0.1878\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0986 - val_loss: 0.2049\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.2081\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1081 - val_loss: 0.1977\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0961 - val_loss: 0.1780\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0969 - val_loss: 0.1993\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1963\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.2012\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.2054\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0882 - val_loss: 0.2436\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1741 - val_loss: 0.1878\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1322 - val_loss: 0.2590\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.2901\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1311 - val_loss: 0.2661\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.2230\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.1861\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0966 - val_loss: 0.2359\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 0.3089\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.2248\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1066 - val_loss: 0.1743\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.1869\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.2268\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.2344\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.1895\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0771 - val_loss: 0.1539\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0747 - val_loss: 0.1646\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.1798\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.1607\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.1717\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0800 - val_loss: 0.1541\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - val_loss: 0.1531\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - val_loss: 0.1728\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0825 - val_loss: 0.1587\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.1717\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.1674\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.1586\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - val_loss: 0.1515\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.1602\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.1709\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0743 - val_loss: 0.1741\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0741 - val_loss: 0.1588\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - val_loss: 0.1461\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.1425\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - val_loss: 0.1761\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.1658\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1011 - val_loss: 0.2166\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.1823\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - val_loss: 0.1783\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - val_loss: 0.1425\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.1383\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - val_loss: 0.1574\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - val_loss: 0.1358\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0564 - val_loss: 0.1370\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - val_loss: 0.1470\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.1433\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.1577\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - val_loss: 0.1456\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.1473\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0723 - val_loss: 0.1516\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0716 - val_loss: 0.1322\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - val_loss: 0.1416\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - val_loss: 0.1395\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.1544\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.1451\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.1453\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - val_loss: 0.1293\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - val_loss: 0.1484\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - val_loss: 0.1601\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.1307\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0520 - val_loss: 0.1256\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.1264\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.1405\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0517 - val_loss: 0.1313\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.1342\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.1274\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.1406\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.1362\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.1831\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.1369\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0794 - val_loss: 0.2136\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - val_loss: 0.1400\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0542 - val_loss: 0.1311\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0528 - val_loss: 0.1348\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0509 - val_loss: 0.1306\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0429 - val_loss: 0.1263\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.1222\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0481 - val_loss: 0.1240\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0430 - val_loss: 0.1230\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0455 - val_loss: 0.1262\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0429 - val_loss: 0.1305\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.1472\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0543 - val_loss: 0.1310\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0516 - val_loss: 0.1462\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0749 - val_loss: 0.1399\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - val_loss: 0.1372\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - val_loss: 0.1191\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0505 - val_loss: 0.1320\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.1144\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.1106\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0434 - val_loss: 0.1222\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0440 - val_loss: 0.1129\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0420 - val_loss: 0.1112\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0408 - val_loss: 0.1045\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.1034\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.1343\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.1245\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.1278\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0380 - val_loss: 0.1084\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0389 - val_loss: 0.1069\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0369 - val_loss: 0.1124\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - val_loss: 0.1079\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0439 - val_loss: 0.1084\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.1170\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.1097\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.1158\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0385 - val_loss: 0.1096\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0501 - val_loss: 0.1197\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.1247\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0368 - val_loss: 0.1098\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0428 - val_loss: 0.1140\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0532 - val_loss: 0.1108\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0406 - val_loss: 0.1245\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - val_loss: 0.1089\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0345 - val_loss: 0.1036\n"
     ]
    }
   ],
   "source": [
    "#   1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(7,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#   2. Compile the model\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "#   3. Implement early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor\n",
    "    patience=20,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Whether to restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "#    4. Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_predicted_ANN = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE, for ANN: 0.82 %\n",
      "MSE, for ANN: 0.1034\n"
     ]
    }
   ],
   "source": [
    "mape_ANN = mean_absolute_percentage_error(Y_val, Y_predicted_ANN)\n",
    "mse_ANN = mean_squared_error(Y_val, Y_predicted_ANN)\n",
    "print(\"MAPE, for ANN:\", format(round(mape_ANN, 4)*100,'.2f'), \"%\")\n",
    "print(\"MSE, for ANN:\", format(round(mse_ANN, 4),'.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2d3bd8790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([28,35], [28, 35], label='y=x', color='gray')\n",
    "\n",
    "plt.scatter(Y_val, Y_predicted_ANN, s=5, label='ANN', color='orange')\n",
    "\n",
    "plt.xlabel('True force [kN]')\n",
    "plt.ylabel('Predicted force [kN]')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
